# Indonesia Dataset

This repository will be used to store Indonesia Dataset. Mostly from translating other dataset.

## Table of contents
  * [Crawl](#crawl)
    * [Twitter Puisi](#twitter-puisi)
  * [Dictionary](#dictionary)
    * [Wordlist](#wordlist)
  * [Dump](#dump)
    * [Neliti](#neliti)
    * [Twitter](#twitter)
  * [Paraphrase](#paraphrase)
    * [PAWS](#paws)
  * [Question Answering](#question-answering)
    * [SQuAD](#squad)
    * [Mathematics Dataset](#mathematics_dataset)
  * [Summarization](#summarization)
    * [WikiHow](#wikihow)

## [Crawl](crawl)

#### [Twitter Puisi](crawl/twitter-puisi)

This dataset contains poem from various user on Twitter. 

## [Dictionary](dictionary)

#### [Wordlist](dictionary/wordlist)

This dataset contains 105,226 words from Kamus Besar Bahasa Indonesia.

## [Dump](dump)

#### [Neliti](dump/neliti)

This dataset is my attempt to replicate [The Pile arXiv](https://arxiv.org/abs/2101.00027). Full data is released now. Contains 280k publications (converted to text) from Neliti.com repository.

#### [Twitter](dump/twitter)

This dataset is crawled from Twitter. Contains the first 100 tweets from random 10k users and filtered using fastText.

## [Paraphrase](paraphrase)

#### [PAWS](paraphrase/paws)

This dataset contains 108,463 human-labeled and 656k noisily labeled pairs that feature the importance of modeling structure, context, and word order information for the problem of paraphrase identification.

## [Question Answering](question-answering)

#### [SQuAD](question-answering/squad)

Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.

#### [Mathematics Dataset](question-answering/mathematics_dataset)

This dataset contains mathematical question and answer pairs, from a range of question types at roughly school-level difficulty. This is designed to test the mathematical learning and algebraic reasoning skills of learning models.

## [Summarization](summarization)

#### [WikiHow](summarization/wikihow)

WikiHow is a new large-scale dataset using the online [WikiHow](https://id.wikihow.com/) knowledge base. Each article consists of multiple paragraphs and each paragraph starts with a sentence summarizing it. By merging the paragraphs to form the article and the paragraph outlines to form the summary.

## Disclaimer

I do not own any of this dataset. Do not use for Commercial Purpose!
